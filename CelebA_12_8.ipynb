{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader,Dataset,Subset,ConcatDataset,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import celeba_dataset\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose([transforms.CenterCrop((178, 178)),\n",
    "                                       transforms.Resize((128, 128)),\n",
    "                                       #transforms.Grayscale(),\n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "### MODEL\n",
    "##########################\n",
    "\n",
    "\n",
    "class VGG16(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "\n",
    "        self.block_1 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          # (1(32-1)- 32 + 3)/2 = 1\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=64,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_2 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=64,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=128,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_3 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=128,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=256,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "\n",
    "\n",
    "        self.block_4 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=256,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.block_5 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels=512,\n",
    "                          out_channels=512,\n",
    "                          kernel_size=(3, 3),\n",
    "                          stride=(1, 1),\n",
    "                          padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                             stride=(2, 2))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Linear(512*4*4, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, 4096),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                #n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                #m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "                m.weight.detach().normal_(0, 0.05)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                m.weight.detach().normal_(0, 0.05)\n",
    "                m.bias.detach().detach().zero_()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = self.block_4(x)\n",
    "        x = self.block_5(x)\n",
    "\n",
    "        logits = self.classifier(x.view(-1, 512*4*4))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "net = VGG16(2)\n",
    "print(net)\n",
    "# 定义损失函数和优化器\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  加载CelebA数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"../celeba/celeba-train.csv\", index_col=0)\n",
    "df_test=pd.read_csv(\"../celeba/celeba-test.csv\",index_col=0)\n",
    "for index,column in enumerate(df_train.columns):\n",
    "    print(str(index)+\" \"+column)\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, df, root_path, transform=None):\n",
    "        self.img_dir = root_path+\"celeba/img_align_celeba/\"\n",
    "        self.img_names = df.index.values\n",
    "        self.y =df.values\n",
    "        self.transform = transform\n",
    "        self.df_box=pd.read_csv('../celeba/list_bbox_celeba.txt', sep=\"\\s+\", skiprows=1,index_col=0)\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        # box=self.df_box.loc[self.img_names[index]]\n",
    "        # img = img.crop([int(box[0]),int(box[1]),int(box[0]+box[2]),int(box[1]+box[3])])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#加载原始数据集\n",
    "celebA_train_dataset=CelebADataset(df_train,\"../\",transform_train)\n",
    "celebA_val_dataset=CelebADataset(df_test,\"../\",transform_train)\n",
    "\n",
    "#取部分数据集\n",
    "# celebA_train_dataset=random_split(celebA_train_dataset,\n",
    "#                                   lengths=[int(len(celebA_train_dataset)*0.25),len(celebA_train_dataset)-int(len(celebA_train_dataset)*0.25)])[0]\n",
    "\n",
    "celebA_train_loader=DataLoader(dataset = celebA_train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_loader=DataLoader(dataset = celebA_val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                             shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"训练集长度：\"+str(len(celebA_train_dataset)) )\n",
    "print(\"验证集长度：\"+str(len(celebA_val_dataset)) )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column1='Smiling'\n",
    "column2='Male'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 构造不平衡数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def splitByRatio(dataset,ratio):\n",
    "    return random_split(dataset,[int(len(dataset)*ratio),len(dataset)-int(len(dataset)*ratio)])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_train_Young0Male0=df_train[(df_train[column1]==0) & (df_train[column2]==0)]\n",
    "df_train_Young0Male1=df_train[(df_train[column1]==0) & (df_train[column2]==1)]\n",
    "df_train_Young1Male0=df_train[(df_train[column1]==1) & (df_train[column2]==0)]\n",
    "df_train_Young1Male1=df_train[(df_train[column1]==1) & (df_train[column2]==1)]\n",
    "train_Young0Male0=CelebADataset(df_train_Young0Male0,\"../\",transform_train)\n",
    "train_Young0Male1=CelebADataset(df_train_Young0Male1,\"../\",transform_train)\n",
    "train_Young1Male0=CelebADataset(df_train_Young1Male0,\"../\",transform_train)\n",
    "train_Young1Male1=CelebADataset(df_train_Young1Male1,\"../\",transform_train)\n",
    "# unbalance_Young_Dataset=ConcatDataset([splitByRatio(train_Young0Male0,0.05)[0],\n",
    "#                                        splitByRatio(train_Young0Male1,1)[0],\n",
    "#                                        splitByRatio(train_Young1Male0,1)[0],\n",
    "#                                        splitByRatio(train_Young1Male1,0.05)[0]])\n",
    "unbalance_Young_Dataset=ConcatDataset([random_split(train_Young0Male0,[10000,len(train_Young0Male0)-10000])[0],\n",
    "                                       random_split(train_Young0Male1,[13000,len(train_Young0Male1)-13000])[0],\n",
    "                                       random_split(train_Young1Male0,[10000,len(train_Young1Male0)-10000])[0],\n",
    "                                       random_split(train_Young1Male1,[7000,len(train_Young1Male1)-7000])[0]\n",
    "                                       ])\n",
    "unbalance_Young_dataloader=DataLoader(unbalance_Young_Dataset,batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(df_test[df_test['Male']==0]))\n",
    "print(len(df_test[df_test['Male']==1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(unbalance_Young_Dataset[0][0].shape)\n",
    "plt.imshow(unbalance_Young_Dataset[166][0].swapaxes(0, 1).swapaxes(1, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 构造平衡数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#ratio为正确标签的比例\n",
    "def shuffle_dataset(dataset,target_index,ratio):\n",
    "    np.random.seed(1)\n",
    "    ds=copy.deepcopy(dataset)\n",
    "    for i,_ in enumerate(ds):\n",
    "        if np.random.rand(1)>ratio:\n",
    "            ds[i][1][target_index]=ds[i][1][target_index]^1\n",
    "    return ds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len_balance=len(unbalance_Young_Dataset)/10\n",
    "balance_Young_Dataset=ConcatDataset([\n",
    "    random_split(train_Young0Male0,[int(len_balance/4),len(train_Young0Male0)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young0Male1,[int(len_balance/4),len(train_Young0Male1)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young1Male0,[int(len_balance/4),len(train_Young1Male0)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young1Male1,[int(len_balance/4),len(train_Young1Male1)-int(len_balance/4)])[0]\n",
    "])\n",
    "balance_Young_dataloader=DataLoader(balance_Young_Dataset,batch_size=batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len_balance=len(unbalance_Young_Dataset)/100\n",
    "shuffle_Young_Dataset=balance_Young_Dataset=ConcatDataset([\n",
    "    random_split(train_Young0Male0,[int(len_balance/4),len(train_Young0Male0)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young0Male1,[int(len_balance/4),len(train_Young0Male1)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young1Male0,[int(len_balance/4),len(train_Young1Male0)-int(len_balance/4)])[0],\n",
    "    random_split(train_Young1Male1,[int(len_balance/4),len(train_Young1Male1)-int(len_balance/4)])[0]\n",
    "])\n",
    "shuffle_Young_Dataset=shuffle_dataset(shuffle_Young_Dataset,target_index=20,ratio=-1)\n",
    "shuffle_Young_dataloader=DataLoader(shuffle_Young_Dataset,batch_size=batch_size,shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 测试集划分"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test_Young0Male0=df_test[(df_test[column1]==0)&(df_test[column2]==0)]\n",
    "df_test_Young0Male1=df_test[(df_test[column1]==0)&(df_test[column2]==1)]\n",
    "df_test_Young1Male0=df_test[(df_test[column1]==1)&(df_test[column2]==0)]\n",
    "df_test_Young1Male1=df_test[(df_test[column1]==1)&(df_test[column2]==1)]\n",
    "Young0Male0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young0Male0,\"../\",transform_train),batch_size=batch_size)\n",
    "Young0Male1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young0Male1,\"../\",transform_train),batch_size=batch_size)\n",
    "Young1Male0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young1Male0,\"../\",transform_train),batch_size=batch_size)\n",
    "Young1Male1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young1Male1,\"../\",transform_train),batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练模型的方法定义\n",
    "\n",
    "def test(loader, net,target_index):\n",
    "    net.eval()\n",
    "    correct_pred=0\n",
    "    num_examples=0\n",
    "    for batch, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target[:,target_index].to(device)\n",
    "        logits, probas = net(data)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += target.size(0)\n",
    "        correct_pred += (predicted_labels == target).sum()\n",
    "        # acc += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        # sum += len(target)\n",
    "        # loss_sum += loss.item()\n",
    "    print('test  acc: %.2f%% ' %(100 * correct_pred.float() / num_examples))\n",
    "    return 100 * correct_pred.float()/ num_examples\n",
    "\n",
    "def train(loader, model, target_index, training_type):\n",
    "    '''\n",
    "    :param loader:\n",
    "    :param model:\n",
    "    :param target_index: 标签下标\n",
    "    :param training_type: 模型名称\n",
    "    :return:\n",
    "    '''\n",
    "    model.train()\n",
    "    sum = 0.0\n",
    "    correct_pred=0.0\n",
    "    for batch, (data, target) in tqdm.tqdm( enumerate(loader),desc=\"模型训练中：\", total=len(loader)):\n",
    "        data, target = data.to(device), target[:,target_index].type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, probas  = model(data)\n",
    "        cost = F.cross_entropy(logits, target)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        _, predicted = torch.max(probas, 1)\n",
    "        sum += target.size(0)\n",
    "        correct_pred += (predicted == target).sum()\n",
    "    acc=100 * correct_pred.float() / sum\n",
    "    print('train acc: %.2f%%' % (acc))\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"../models/22_12_18/\" + str(training_type) + \"_checkpoint.pth\")\n",
    "    if correct_pred==sum:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def CelebA_test(model,target_index):\n",
    "    print(\"全部测试集：\")\n",
    "    test(celebA_val_loader,model,target_index=target_index)\n",
    "    print(\"Young0Male0测试集：\")\n",
    "    acc1=test(Young0Male0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Young0Male1测试集：\")\n",
    "    acc2=test(Young0Male1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Young1Male0测试集：\")\n",
    "    acc3=test(Young1Male0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Young1Male1测试集：\")\n",
    "    acc4=test(Young1Male1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"方差：\")\n",
    "    print(np.var([acc1.item(),acc2.item(),acc3.item(),acc4.item()]))\n",
    "\n",
    "\n",
    "def load_model(model_path=None):\n",
    "    net = VGG16(2)\n",
    "    global optimizer\n",
    "    optimizer= torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    if model_path!=None:\n",
    "        checkpoint = torch.load(model_path)\n",
    "        net.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    # if torch.cuda.device_count() > 1:\n",
    "    #     print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    #     net= nn.DataParallel(net)\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=load_model('../models/22_12_17/VGG16_shuffle_male_smiling_checkpoint.pth')\n",
    "CelebA_test(net,20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "#原始训练\n",
    "net=load_model()\n",
    "for epoch in range(50):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(unbalance_Young_dataloader,net,target_index=20,training_type=\"VGG16_unbalance_male_smiling\")#后两个标签_敏感特征\n",
    "        if (epoch+1)%5==0:\n",
    "            CelebA_test(net,target_index=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=load_model('../models/22_12_17/VGG16_unbalance_male_smiling_checkpoint.pth')\n",
    "for epoch in range(1):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(shuffle_Young_dataloader,net,target_index=20,training_type=\"VGG16_shuffle_male_smiling\")\n",
    "CelebA_test(net,target_index=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:06<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 84.60%\n",
      "epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:06<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 86.80%\n",
      "epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:06<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 86.78%\n",
      "epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:06<00:00,  5.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.08%\n",
      "epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:06<00:00,  5.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 91.23%\n",
      "epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：:  53%|████████████████████████████████████████████████████████████████████████▎                                                               | 17/32 [00:03<00:03,  4.80it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#恢复训练\n",
    "net1=load_model('../models/22_12_18/VGG16_shuffle_male_smiling_checkpoint.pth')\n",
    "for epoch in range(1000):\n",
    "        print('epoch: %d' % epoch)\n",
    "        acc=train(balance_Young_dataloader,net1,target_index=20,training_type=\"VGG16_balance_male_smiling\")\n",
    "        if acc :\n",
    "            break\n",
    "CelebA_test(net1,target_index=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net2=load_model('../models/22_12_17/VGG16_unbalance_male_smiling_checkpoint.pth')\n",
    "for epoch in range(1000):\n",
    "        print('epoch: %d' % epoch)\n",
    "        acc=train(balance_Young_dataloader,net2,target_index=20,training_type=\"VGG16_onlybalance_male_smiling\")\n",
    "        if acc:\n",
    "            break\n",
    "CelebA_test(net2,target_index=20)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%a'c'c\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
