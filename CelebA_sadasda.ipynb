{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader,Dataset,Subset,ConcatDataset,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhixin/Project/FL_CelebA_10_27\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据缩放到（-1，1）\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                       transforms.Resize((128, 128)),\n",
    "                                       #transforms.Grayscale(),\n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512*4*4, 2)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "\n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=8192, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = VGG(net_name)\n",
    "print(net)\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_2 = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  加载CelebA数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5_o_Clock_Shadow\n",
      "1 Arched_Eyebrows\n",
      "2 Attractive\n",
      "3 Bags_Under_Eyes\n",
      "4 Bald\n",
      "5 Bangs\n",
      "6 Big_Lips\n",
      "7 Big_Nose\n",
      "8 Black_Hair\n",
      "9 Blond_Hair\n",
      "10 Blurry\n",
      "11 Brown_Hair\n",
      "12 Bushy_Eyebrows\n",
      "13 Chubby\n",
      "14 Double_Chin\n",
      "15 Eyeglasses\n",
      "16 Goatee\n",
      "17 Gray_Hair\n",
      "18 Heavy_Makeup\n",
      "19 High_Cheekbones\n",
      "20 Male\n",
      "21 Mouth_Slightly_Open\n",
      "22 Mustache\n",
      "23 Narrow_Eyes\n",
      "24 No_Beard\n",
      "25 Oval_Face\n",
      "26 Pale_Skin\n",
      "27 Pointy_Nose\n",
      "28 Receding_Hairline\n",
      "29 Rosy_Cheeks\n",
      "30 Sideburns\n",
      "31 Smiling\n",
      "32 Straight_Hair\n",
      "33 Wavy_Hair\n",
      "34 Wearing_Earrings\n",
      "35 Wearing_Hat\n",
      "36 Wearing_Lipstick\n",
      "37 Wearing_Necklace\n",
      "38 Wearing_Necktie\n",
      "39 Young\n"
     ]
    },
    {
     "data": {
      "text/plain": "            5_o_Clock_Shadow  Arched_Eyebrows  Attractive  Bags_Under_Eyes  \\\n000001.jpg                 0                1           1                0   \n000002.jpg                 0                0           0                1   \n000003.jpg                 0                0           0                0   \n000004.jpg                 0                0           1                0   \n000005.jpg                 0                1           1                0   \n\n            Bald  Bangs  Big_Lips  Big_Nose  Black_Hair  Blond_Hair  ...  \\\n000001.jpg     0      0         0         0           0           0  ...   \n000002.jpg     0      0         0         1           0           0  ...   \n000003.jpg     0      0         1         0           0           0  ...   \n000004.jpg     0      0         0         0           0           0  ...   \n000005.jpg     0      0         1         0           0           0  ...   \n\n            Sideburns  Smiling  Straight_Hair  Wavy_Hair  Wearing_Earrings  \\\n000001.jpg          0        1              1          0                 1   \n000002.jpg          0        1              0          0                 0   \n000003.jpg          0        0              0          1                 0   \n000004.jpg          0        0              1          0                 1   \n000005.jpg          0        0              0          0                 0   \n\n            Wearing_Hat  Wearing_Lipstick  Wearing_Necklace  Wearing_Necktie  \\\n000001.jpg            0                 1                 0                0   \n000002.jpg            0                 0                 0                0   \n000003.jpg            0                 0                 0                0   \n000004.jpg            0                 1                 1                0   \n000005.jpg            0                 1                 0                0   \n\n            Young  \n000001.jpg      1  \n000002.jpg      1  \n000003.jpg      1  \n000004.jpg      1  \n000005.jpg      1  \n\n[5 rows x 40 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5_o_Clock_Shadow</th>\n      <th>Arched_Eyebrows</th>\n      <th>Attractive</th>\n      <th>Bags_Under_Eyes</th>\n      <th>Bald</th>\n      <th>Bangs</th>\n      <th>Big_Lips</th>\n      <th>Big_Nose</th>\n      <th>Black_Hair</th>\n      <th>Blond_Hair</th>\n      <th>...</th>\n      <th>Sideburns</th>\n      <th>Smiling</th>\n      <th>Straight_Hair</th>\n      <th>Wavy_Hair</th>\n      <th>Wearing_Earrings</th>\n      <th>Wearing_Hat</th>\n      <th>Wearing_Lipstick</th>\n      <th>Wearing_Necklace</th>\n      <th>Wearing_Necktie</th>\n      <th>Young</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>000001.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>000002.jpg</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>000003.jpg</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>000004.jpg</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>000005.jpg</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"../celeba/celeba-train.csv\", index_col=0)\n",
    "df_test=pd.read_csv(\"../celeba/celeba-test.csv\",index_col=0)\n",
    "for index,column in enumerate(df_train.columns):\n",
    "    print(str(index)+\" \"+column)\n",
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, df, root_path, transform=None):\n",
    "        self.img_dir = root_path+\"celeba/img_align_celeba/\"\n",
    "        self.img_names = df.index.values\n",
    "        self.y =df.values\n",
    "        self.transform = transform\n",
    "        self.df_box=pd.read_csv('../celeba/list_bbox_celeba.txt', sep=\"\\s+\", skiprows=1,index_col=0)\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        box=self.df_box.loc[self.img_names[index]]\n",
    "        img = img.crop([int(box[0]),int(box[1]),int(box[0]+box[2]),int(box[1]+box[3])])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#加载原始数据集\n",
    "celebA_train_dataset=CelebADataset(df_train,\"../\",transform_train)\n",
    "celebA_val_dataset=CelebADataset(df_test,\"../\",transform_train)\n",
    "\n",
    "#取部分数据集\n",
    "# celebA_train_dataset=random_split(celebA_train_dataset,\n",
    "#                                   lengths=[int(len(celebA_train_dataset)*0.25),len(celebA_train_dataset)-int(len(celebA_train_dataset)*0.25)])[0]\n",
    "\n",
    "celebA_train_loader=DataLoader(dataset = celebA_train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_loader=DataLoader(dataset = celebA_val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                             shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集长度：162770\n",
      "验证集长度：19962\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集长度：\"+str(len(celebA_train_dataset)) )\n",
    "print(\"验证集长度：\"+str(len(celebA_val_dataset)) )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17667\n",
      "67023\n",
      "18315\n",
      "59765\n"
     ]
    }
   ],
   "source": [
    "df_train_Young0Male0=df_train[(df_train['Smiling']==0) & (df_train['Young']==0)]\n",
    "df_train_Young0Male1=df_train[(df_train['Smiling']==0) & (df_train['Young']==1)]\n",
    "df_train_Young1Male0=df_train[(df_train['Smiling']==1) & (df_train['Young']==0)]\n",
    "df_train_Young1Male1=df_train[(df_train['Smiling']==1) & (df_train['Young']==1)]\n",
    "print(len(df_train_Young0Male0))\n",
    "print(len(df_train_Young0Male1))\n",
    "print(len(df_train_Young1Male0))\n",
    "print(len(df_train_Young1Male1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_test_Male0=df_test[df_test['Male']==0]\n",
    "df_test_Male1=df_test[df_test['Male']==1]\n",
    "df_test_Young0=df_test[df_test['Young']==0]\n",
    "df_test_Young1=df_test[df_test['Young']==1]\n",
    "df_test_Bald0=df_test[df_test[\"Bald\"]==0]\n",
    "df_test_Bald1=df_test[df_test[\"Bald\"]==1]\n",
    "df_test_Eyeglasses0=df_test[df_test[\"Eyeglasses\"]==0]\n",
    "df_test_Eeyeglasses1=df_test[df_test[\"Eyeglasses\"]==1]\n",
    "df_test_Wearing_earrings0=df_test[df_test[\"Wearing_Earrings\"]==0]\n",
    "df_test_Wearing_earrings1=df_test[df_test[\"Wearing_Earrings\"]==1]\n",
    "df_test_Receding_hairing0=df_test[df_test[\"Receding_Hairline\"]==0]\n",
    "df_test_Receding_hairing1=df_test[df_test[\"Receding_Hairline\"]==1]\n",
    "Male0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Male0,\"../\",transform_train),batch_size=batch_size)\n",
    "Male1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Male1,\"../\",transform_train),batch_size=batch_size)\n",
    "Young0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young0,\"../\",transform_train),batch_size=batch_size)\n",
    "Young1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Young1,\"../\",transform_train),batch_size=batch_size)\n",
    "Bald0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Bald0,\"../\",transform_train),batch_size=batch_size)\n",
    "Bald1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Bald1,\"../\",transform_train),batch_size=batch_size)\n",
    "Eyeglasses0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Eyeglasses0,\"../\",transform_train),batch_size=batch_size)\n",
    "Eyeglasses1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Eeyeglasses1,\"../\",transform_train),batch_size=batch_size)\n",
    "Wearing_earrings0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Wearing_earrings0,\"../\",transform_train),batch_size=batch_size)\n",
    "Wearing_earrings1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Wearing_earrings1,\"../\",transform_train),batch_size=batch_size)\n",
    "Receding_hairing0_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Receding_hairing0,\"../\",transform_train),batch_size=batch_size)\n",
    "Receding_hairing1_test_DataLoader=DataLoader(dataset=CelebADataset(df_test_Receding_hairing1,\"../\",transform_train),batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def shuffle_dataset(dataset,target_index):\n",
    "    '''\n",
    "    打乱数据集，把目标标签取反\n",
    "    :param dataset:\n",
    "    :param target_index: 标签下标\n",
    "    :return:\n",
    "    '''\n",
    "    dataset=copy.deepcopy(dataset)\n",
    "    for i,(data,target) in enumerate(dataset):\n",
    "        dataset[i][1][target_index]=target[target_index]^1 #取反操作\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#标签的下标\n",
    "target_index=20\n",
    "#身份标签的下标\n",
    "group_index=20\n",
    "#shuffle数据集的长度\n",
    "shuffle_len=len(celebA_train_dataset)/10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices=get_split_indices(celebA_train_dataset,target_index)\n",
    "celebA_train_target1_dataset=Subset(celebA_train_dataset,indices[0])\n",
    "celebA_train_target2_dataset=Subset(celebA_train_dataset,indices[1])\n",
    "#构造一个标签平衡的训练集\n",
    "length=15000\n",
    "# celebA_train_dataset=ConcatDataset([random_split(celebA_train_target1_dataset,[length,len(celebA_train_target1_dataset)-length])[0],random_split(celebA_train_target2_dataset,[length,len(celebA_train_target2_dataset)-length])[0]])\n",
    "# celebA_train_loader=DataLoader(dataset = celebA_train_dataset,\n",
    "#                               batch_size=batch_size,\n",
    "#                               shuffle=True)\n",
    "print(len(celebA_train_target1_dataset))\n",
    "print(len(celebA_train_target2_dataset))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练模型的方法定义\n",
    "def test(loader, net,target_index):\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "    for batch, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target[:,target_index].to(device)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "        # acc += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        # sum += len(target)\n",
    "        # loss_sum += loss.item()\n",
    "    print('test  acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    return 100 * acc / sum, loss_sum / (batch + 1)\n",
    "\n",
    "def train(loader, model, target_index, training_type):\n",
    "    '''\n",
    "    :param loader:\n",
    "    :param model:\n",
    "    :param target_index: 标签下标\n",
    "    :param training_type: 模型名称\n",
    "    :return:\n",
    "    '''\n",
    "    model.train()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    for batch, (data, target) in tqdm.tqdm( enumerate(loader),desc=\"模型训练中：\", total=len(loader)):\n",
    "        data, target = data.to(device), target[:,target_index].type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "\n",
    "    print('train acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"../models/\" + str(training_type) + \"_checkpoint.pth\")\n",
    "\n",
    "def load_model(model_path):\n",
    "    #加载模型\n",
    "    net = VGG('VGG16').to(device)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return net\n",
    "def CelebA_test(model,target_index):\n",
    "    print(\"全部测试集：\")\n",
    "    acc,loss=test(celebA_val_loader,model,target_index=target_index)\n",
    "    print(\"性别1测试集：\")\n",
    "    test(Male0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"性别2测试集：\")\n",
    "    test(Male1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Young0测试集：\")\n",
    "    test(Young0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Young1测试集：\")\n",
    "    test(Young1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Bald0测试集：\")\n",
    "    test(Bald0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Bald1测试集：\")\n",
    "    test(Bald1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Wearing_earrings0测试集：\")\n",
    "    test(Wearing_earrings0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Wearing_earrings1测试集：\")\n",
    "    test(Wearing_earrings1_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Receding_hairing0测试集：\")\n",
    "    test(Receding_hairing0_test_DataLoader,model,target_index=target_index)\n",
    "    print(\"Receding_hairing1测试集：\")\n",
    "    test(Receding_hairing1_test_DataLoader,model,target_index=target_index)\n",
    "    return acc\n",
    "def load_new_model():\n",
    "    net = VGG(net_name)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "        net = nn.DataParallel(net)\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=load_model(\"../models/VGG16_origin_gender_checkpoint.pth\")\n",
    "CelebA_test(net,30)\n",
    "net=load_model(\"../models/VGG16_origin_smiling_checkpoint.pth\")\n",
    "CelebA_test(net,31)\n",
    "net=load_model(\"../models/VGG16_origin_biglips_checkpoint.pth\")\n",
    "CelebA_test(net,6)\n",
    "net=load_model(\"../models/VGG16_origin_bignose_checkpoint.pth\")\n",
    "CelebA_test(net,7)\n",
    "net=load_model(\"../models/VGG16_origin_wavyhair_checkpoint.pth\")\n",
    "CelebA_test(net,33)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [07:02<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 94.33%, loss: 0.2161\n",
      "全部测试集：\n",
      "test  acc: 95.38%, loss: 0.1876\n",
      "epoch:0\n",
      "CPU times: user 1h 46min 13s, sys: 41.6 s, total: 1h 46min 55s\n",
      "Wall time: 7min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#原始训练\n",
    "net=load_new_model()\n",
    "for epoch in range(200):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=30,training_type=\"VGG16_origin_gender\")\n",
    "        acc=CelebA_test(net,target_index=30)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n",
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：:  15%|████████████████████▍                                                                                                                | 195/1272 [01:04<05:52,  3.06it/s]"
     ]
    }
   ],
   "source": [
    "net=load_new_model()\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=31,training_type=\"VGG16_origin_smiling\")\n",
    "        acc=CelebA_test(net,target_index=31)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break\n",
    "net=load_new_model()\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=6,training_type=\"VGG16_origin_biglips\")\n",
    "        acc=CelebA_test(net,target_index=6)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break\n",
    "\n",
    "net=load_new_model()\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=7,training_type=\"VGG16_origin_bignose\")\n",
    "        acc=CelebA_test(net,target_index=7)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break\n",
    "net=load_new_model()\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=33,training_type=\"VGG16_origin_wavyhair\")\n",
    "        acc=CelebA_test(net,target_index=33)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:27<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 64.74%, loss: 0.6459\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 71.83%, loss: 0.5081\n"
     ]
    }
   ],
   "source": [
    "#混淆训练,celebA数据集target为biglips\n",
    "for epoch in range(2):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_shuffle_biglips_dataloader,net,target_index=target_index,training_type=\"VGG16(224*224)_shuffle_smiling\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "net=load_model('../models/VGG16(224*224)_shuffle_smiling_checkpoint.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部测试集：\n",
      "test  acc: 33.74%, loss: 2.0693\n",
      "性别1测试集：\n",
      "test  acc: 33.47%, loss: 2.1568\n",
      "性别2测试集：\n",
      "test  acc: 34.91%, loss: 1.9318\n",
      "标签1测试集：\n",
      "test  acc: 38.15%, loss: 0.7709\n",
      "标签2测试集：\n",
      "test  acc: 29.84%, loss: 3.3945\n"
     ]
    }
   ],
   "source": [
    "CelebA_test(net,target_index=target_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.19%, loss: 0.2132\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.63%, loss: 0.2047\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.84%, loss: 0.1975\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.89%, loss: 0.1970\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.01%, loss: 0.1938\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.12%, loss: 0.1897\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.10%, loss: 0.1882\n",
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.12%, loss: 0.1880\n",
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.14%, loss: 0.1881\n",
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.17%, loss: 0.1874\n"
     ]
    }
   ],
   "source": [
    "#恢复训练,celebA数据集target为biglips\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_balance_dataloader,net,target_index=target_index,training_type=\"VGG16(224*224)_balance_smiling\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "net=load_model('../models/VGG16(224*224)_balance_smiling_checkpoint.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部测试集：\n",
      "test  acc: 72.26%, loss: 0.9061\n",
      "性别1测试集：\n",
      "test  acc: 70.07%, loss: 0.8734\n",
      "性别2测试集：\n",
      "test  acc: 75.74%, loss: 0.9761\n",
      "标签1测试集：\n",
      "test  acc: 82.18%, loss: 0.9227\n",
      "标签2测试集：\n",
      "test  acc: 61.94%, loss: 0.8948\n"
     ]
    }
   ],
   "source": [
    "CelebA_test(net,target_index=target_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
