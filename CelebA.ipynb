{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import scipy\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets as ds\n",
    "from torch.utils.data import DataLoader,Dataset,Subset,ConcatDataset,random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import celeba_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/zhixin/Project/FL_CelebA_10_27\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据缩放到（-1，1）\n",
    "class Oneone(torch.nn.Module):\n",
    "    def __init__(self, inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, tensor):\n",
    "        return tensor*2.0-1.0\n",
    "        # return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "# transform = transforms.Compose是把一系列图片操作组合起来，比如减去像素均值等。\n",
    "# DataLoader读入的数据类型是PIL.Image\n",
    "# 这里对图片不做任何处理，仅仅是把PIL.Image转换为torch.FloatTensor，从而可以被pytorch计算\n",
    "transform_train = transforms.Compose([transforms.CenterCrop(224),\n",
    "                                       transforms.Resize((128, 128)),\n",
    "                                       #transforms.Grayscale(),\n",
    "                                       #transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    Oneone(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "intermediate_result = {}\n",
    "net_name = \"VGG16\"\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512*4*4, 2)\n",
    "        global intermediate_result\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq = self.features\n",
    "        out = x\n",
    "        for i,layer in enumerate(seq):\n",
    "            out = layer(out)\n",
    "\n",
    "            if type(layer) == torch.nn.modules.conv.Conv2d:\n",
    "                intermediate_result[str(i)] = out\n",
    "#         out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        intermediate_result[\"linear\"] = out\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=8192, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = VGG(net_name)\n",
    "print(net)\n",
    "# 定义损失函数和优化器\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "optimizer_2 = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "\n",
    "\n",
    "# 如果有gpu就使用gpu，否则使用cpu\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = net.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#  加载CelebA数据集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#加载原始数据集\n",
    "celebA_train_dataset=celeba_dataset.CelebA(root='../', split='train',target_type='attr', transform=transform_train, target_transform=None, download=True)\n",
    "celebA_val_dataset=celeba_dataset.CelebA(root='../', split='test',target_type='attr',transform=transform_train, target_transform=None, download=True)\n",
    "\n",
    "#取部分数据集\n",
    "# celebA_train_dataset=random_split(celebA_train_dataset,\n",
    "#                                   lengths=[int(len(celebA_train_dataset)*0.25),len(celebA_train_dataset)-int(len(celebA_train_dataset)*0.25)])[0]\n",
    "\n",
    "celebA_train_loader=DataLoader(dataset = celebA_train_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_loader=DataLoader(dataset = celebA_val_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "标签参数如下\n",
      "0 5_o_Clock_Shadow\n",
      "1 Arched_Eyebrows\n",
      "2 Attractive\n",
      "3 Bags_Under_Eyes\n",
      "4 Bald\n",
      "5 Bangs\n",
      "6 Big_Lips\n",
      "7 Big_Nose\n",
      "8 Black_Hair\n",
      "9 Blond_Hair\n",
      "10 Blurry\n",
      "11 Brown_Hair\n",
      "12 Bushy_Eyebrows\n",
      "13 Chubby\n",
      "14 Double_Chin\n",
      "15 Eyeglasses\n",
      "16 Goatee\n",
      "17 Gray_Hair\n",
      "18 Heavy_Makeup\n",
      "19 High_Cheekbones\n",
      "20 Male\n",
      "21 Mouth_Slightly_Open\n",
      "22 Mustache\n",
      "23 Narrow_Eyes\n",
      "24 No_Beard\n",
      "25 Oval_Face\n",
      "26 Pale_Skin\n",
      "27 Pointy_Nose\n",
      "28 Receding_Hairline\n",
      "29 Rosy_Cheeks\n",
      "30 Sideburns\n",
      "31 Smiling\n",
      "32 Straight_Hair\n",
      "33 Wavy_Hair\n",
      "34 Wearing_Earrings\n",
      "35 Wearing_Hat\n",
      "36 Wearing_Lipstick\n",
      "37 Wearing_Necklace\n",
      "38 Wearing_Necktie\n",
      "39 Young\n",
      "40 \n",
      "训练集长度：162770\n",
      "验证集长度：19962\n"
     ]
    }
   ],
   "source": [
    "print(\"标签参数如下\")\n",
    "for i,name in enumerate(celebA_val_dataset.attr_names):\n",
    "    print(str(i)+\" \"+name)\n",
    "\n",
    "print(\"训练集长度：\"+str(len(celebA_train_dataset)) )\n",
    "print(\"验证集长度：\"+str(len(celebA_val_dataset)) )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#数据切分加工\n",
    "def get_split_indices(dataset,target_index):\n",
    "    '''\n",
    "    按标签划分数据集，返回数据集的下标集合\n",
    "    :param dataset:\n",
    "    :param target_index: 按照这个下标的标签进行划分\n",
    "    :return: 返回的list中，每个元素代表不同值的标签下标的集合\n",
    "    '''\n",
    "    group1=[]\n",
    "    group2=[]\n",
    "    for i,(data,target) in enumerate(dataset):\n",
    "        if target[target_index]==0:\n",
    "            group1.append(i)\n",
    "        else:\n",
    "            group2.append(i)\n",
    "    return [group1,group2]\n",
    "def shuffle_dataset(dataset,target_index):\n",
    "    '''\n",
    "    打乱数据集，把目标标签取反\n",
    "    :param dataset:\n",
    "    :param target_index: 标签下标\n",
    "    :return:\n",
    "    '''\n",
    "    dataset=copy.deepcopy(dataset)\n",
    "    for i,(data,target) in enumerate(dataset):\n",
    "        dataset[i][1][target_index]=target[target_index]^1 #取反操作\n",
    "    return dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#标签的下标\n",
    "target_index=20\n",
    "#身份标签的下标\n",
    "group_index=20\n",
    "#shuffle数据集的长度\n",
    "shuffle_len=len(celebA_train_dataset)/10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_245007/3785482566.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mindices\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mget_split_indices\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcelebA_train_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtarget_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mcelebA_train_target1_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mSubset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcelebA_train_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mcelebA_train_target2_dataset\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mSubset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcelebA_train_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mindices\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#构造一个标签平衡的训练集\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mlength\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m15000\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_245007/305082530.py\u001B[0m in \u001B[0;36mget_split_indices\u001B[0;34m(dataset, target_index)\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mgroup1\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0mgroup2\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtarget_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m             \u001B[0mgroup1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Project/FL_CelebA_10_27/celeba_dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 183\u001B[0;31m             \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    185\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, img)\u001B[0m\n\u001B[1;32m     59\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     60\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtransforms\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 61\u001B[0;31m             \u001B[0mimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     62\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     63\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, pic)\u001B[0m\n\u001B[1;32m     96\u001B[0m             \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConverted\u001B[0m \u001B[0mimage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     97\u001B[0m         \"\"\"\n\u001B[0;32m---> 98\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_tensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     99\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__repr__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001B[0m in \u001B[0;36mto_tensor\u001B[0;34m(pic)\u001B[0m\n\u001B[1;32m    138\u001B[0m     \u001B[0;31m# handle PIL Image\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0mmode_to_nptype\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m'I'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint32\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'I;16'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint16\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'F'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat32\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m     img = torch.from_numpy(\n\u001B[0m\u001B[1;32m    141\u001B[0m         \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode_to_nptype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpic\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muint8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m     )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "indices=get_split_indices(celebA_train_dataset,target_index)\n",
    "celebA_train_target1_dataset=Subset(celebA_train_dataset,indices[0])\n",
    "celebA_train_target2_dataset=Subset(celebA_train_dataset,indices[1])\n",
    "#构造一个标签平衡的训练集\n",
    "length=15000\n",
    "# celebA_train_dataset=ConcatDataset([random_split(celebA_train_target1_dataset,[length,len(celebA_train_target1_dataset)-length])[0],random_split(celebA_train_target2_dataset,[length,len(celebA_train_target2_dataset)-length])[0]])\n",
    "# celebA_train_loader=DataLoader(dataset = celebA_train_dataset,\n",
    "#                               batch_size=batch_size,\n",
    "#                               shuffle=True)\n",
    "print(len(celebA_train_target1_dataset))\n",
    "print(len(celebA_train_target2_dataset))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#加载划分数据集\n",
    "#男女验证集\n",
    "indices=get_split_indices(celebA_val_dataset,group_index)\n",
    "celebA_val_male1_dataset=Subset(celebA_val_dataset,indices[0])\n",
    "celebA_val_male2_dataset=Subset(celebA_val_dataset,indices[1])\n",
    "celebA_val_male1_loader=DataLoader(dataset = celebA_val_male1_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_male2_loader=DataLoader(dataset = celebA_val_male2_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "#男女性训练集\n",
    "indices=get_split_indices(celebA_train_dataset,group_index)\n",
    "celebA_train_male1_dataset=Subset(celebA_train_dataset,indices[0])\n",
    "celebA_train_male2_dataset=Subset(celebA_train_dataset,indices[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#验证集\n",
    "#性别1中biglips标签数据集\n",
    "indices = get_split_indices(celebA_val_male1_dataset, target_index)\n",
    "celebA_val_male1_biglips1_dataset = Subset(celebA_val_male1_dataset, indices[0])\n",
    "celebA_val_male1_biglips2_dataset = Subset(celebA_val_male1_dataset, indices[1])\n",
    "celebA_val_male1_biglips1_loader=DataLoader(dataset = celebA_val_male1_biglips1_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_male1_biglips2_loader=DataLoader(dataset = celebA_val_male1_biglips2_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "#性别2中biglips标签数据集\n",
    "indices = get_split_indices(celebA_val_male2_dataset, target_index)\n",
    "celebA_val_male2_biglips1_dataset = Subset(celebA_val_male2_dataset, indices[0])\n",
    "celebA_val_male2_biglips2_dataset = Subset(celebA_val_male2_dataset, indices[1])\n",
    "celebA_val_male2_biglips1_loader=DataLoader(dataset = celebA_val_male2_biglips1_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_male2_biglips2_loader=DataLoader(dataset = celebA_val_male2_biglips2_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "indices=get_split_indices(celebA_val_dataset,target_index)\n",
    "celebA_val_biglips1_dataset=Subset(celebA_val_dataset,indices[0])\n",
    "celebA_val_biglips2_dataset=Subset(celebA_val_dataset,indices[1])\n",
    "celebA_val_biglips1_loader=DataLoader(dataset =celebA_val_biglips1_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_val_biglips2_loader=DataLoader(dataset =celebA_val_biglips2_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#训练集\n",
    "#性别1中biglips标签数据集\n",
    "indices=get_split_indices(celebA_train_male1_dataset,target_index)\n",
    "celebA_train_male1_biglips1_dataset=Subset(celebA_train_male1_dataset,indices[0])\n",
    "celebA_train_male1_biglips2_dataset=Subset(celebA_train_male1_dataset,indices[1])\n",
    "#性别2中biglips标签数据集\n",
    "indices=get_split_indices(celebA_train_male2_dataset,target_index)\n",
    "celebA_train_male2_biglips1_dataset=Subset(celebA_train_male2_dataset,indices[0])\n",
    "celebA_train_male2_biglips2_dataset=Subset(celebA_train_male2_dataset,indices[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "#shuffle数据集，含50个男正例、反例和女性正例反例的数据集，并打乱biglips\n",
    "# celebA_train_balance_dataset=ConcatDataset([Subset(celebA_train_male1_biglips1_dataset,range(100)),\n",
    "#                                             Subset(celebA_train_male1_biglips2_dataset,range(100)),\n",
    "#                                             Subset(celebA_train_male2_biglips1_dataset,range(100)),\n",
    "#                                             Subset(celebA_train_male2_biglips2_dataset,range(100))] )\n",
    "# celebA_train_balance_dataset=ConcatDataset([Subset(celebA_train_male1_dataset,range(100)),\n",
    "#                                             Subset(celebA_train_male2_dataset,range(100))] )\n",
    "# celebA_train_balance_dataset=ConcatDataset([random_split(celebA_train_male1_dataset,[100,len(celebA_train_male1_dataset)-100])[0],\n",
    "#                                             random_split(celebA_train_male2_dataset,[100,len(celebA_train_male2_dataset)-100])[0]] )\n",
    "celebA_train_balance_dataset=ConcatDataset([random_split(celebA_train_male1_biglips1_dataset,[int(shuffle_len/4),len(celebA_train_male1_biglips1_dataset)-int(shuffle_len/4)])[0],\n",
    "                                            random_split(celebA_train_male1_biglips2_dataset,[int(shuffle_len/4),len(celebA_train_male1_biglips2_dataset)-int(shuffle_len/4)])[0],\n",
    "                                            random_split(celebA_train_male2_biglips1_dataset,[int(shuffle_len/4),len(celebA_train_male2_biglips1_dataset)-int(shuffle_len/4)])[0],\n",
    "                                            random_split(celebA_train_male2_biglips2_dataset,[int(shuffle_len/4),len(celebA_train_male2_biglips2_dataset)-int(shuffle_len/4)])[0]] )\n",
    "celebA_train_shuffle_biglips_dataset=shuffle_dataset(celebA_train_balance_dataset,target_index=target_index)\n",
    "celebA_train_balance_dataloader=DataLoader(dataset = celebA_train_balance_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)\n",
    "celebA_train_shuffle_biglips_dataloader=DataLoader(dataset = celebA_train_shuffle_biglips_dataset,\n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on:  cuda\n"
     ]
    }
   ],
   "source": [
    "# 训练模型的方法定义\n",
    "print('training on: ', device)\n",
    "def test(loader, net,target_index):\n",
    "    net.eval()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "    for batch, (data, target) in enumerate(loader):\n",
    "        data, target = data.to(device), target[:,target_index].to(device)\n",
    "        output = net(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "        # acc += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        # sum += len(target)\n",
    "        # loss_sum += loss.item()\n",
    "    print('test  acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    return 100 * acc / sum, loss_sum / (batch + 1)\n",
    "\n",
    "def train(loader, model, target_index, training_type):\n",
    "    '''\n",
    "    :param loader:\n",
    "    :param model:\n",
    "    :param target_index: 标签下标\n",
    "    :param training_type: 模型名称\n",
    "    :return:\n",
    "    '''\n",
    "    model.train()\n",
    "    acc = 0.0\n",
    "    sum = 0.0\n",
    "    loss_sum = 0\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "    for batch, (data, target) in tqdm.tqdm( enumerate(loader),desc=\"模型训练中：\", total=len(loader)):\n",
    "        data, target = data.to(device), target[:,target_index].type(torch.LongTensor).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        sum += target.size(0)\n",
    "        acc += predicted.eq(target).sum().item()\n",
    "\n",
    "    print('train acc: %.2f%%, loss: %.4f' % (100 * acc / sum, loss_sum / (batch + 1)))\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, \"../models/\" + str(training_type) + \"_checkpoint.pth\")\n",
    "\n",
    "def load_model(model_path):\n",
    "    #加载模型\n",
    "    net = VGG('VGG16').to(device)\n",
    "    checkpoint = torch.load(model_path)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    return net\n",
    "def CelebA_test(model,target_index):\n",
    "    print(\"全部测试集：\")\n",
    "    acc,loss=test(celebA_val_loader,model,target_index=target_index)\n",
    "    # print(\"性别1测试集：\")\n",
    "    # test(celebA_val_male1_loader,model,target_index=target_index)\n",
    "    # print(\"性别2测试集：\")\n",
    "    # test(celebA_val_male2_loader,model,target_index=target_index)\n",
    "    # print(\"标签1测试集：\")\n",
    "    # test(celebA_val_biglips1_loader,model,target_index=target_index)\n",
    "    # print(\"标签2测试集：\")\n",
    "    # test(celebA_val_biglips2_loader,model,target_index=target_index)\n",
    "    return acc\n",
    "def load_new_model():\n",
    "    net = VGG(net_name)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    net = net.to(device)\n",
    "    net= nn.DataParallel(net)\n",
    "    return net"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    net= nn.DataParallel(net)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:25<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 94.32%, loss: 0.2193\n",
      "全部测试集：\n",
      "test  acc: 95.31%, loss: 0.1729\n",
      "epoch:0\n",
      "CPU times: user 2h 14min 55s, sys: 5min 26s, total: 2h 20min 22s\n",
      "Wall time: 7min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#原始训练\n",
    "for epoch in range(200):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=30,training_type=\"VGG16_origin_gender\")\n",
    "        acc=CelebA_test(net,target_index=30)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:49<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 68.52%, loss: 0.6441\n",
      "全部测试集：\n",
      "test  acc: 63.68%, loss: 0.6398\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:48<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 71.74%, loss: 0.5881\n",
      "全部测试集：\n",
      "test  acc: 70.04%, loss: 0.5826\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:47<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 72.45%, loss: 0.5803\n",
      "全部测试集：\n",
      "test  acc: 70.69%, loss: 0.6207\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:47<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 72.99%, loss: 0.5589\n",
      "全部测试集：\n",
      "test  acc: 71.27%, loss: 0.5685\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:48<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 73.49%, loss: 0.5466\n",
      "全部测试集：\n",
      "test  acc: 70.27%, loss: 0.5694\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:46<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 73.77%, loss: 0.5389\n",
      "全部测试集：\n",
      "test  acc: 69.53%, loss: 0.6297\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:47<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 74.09%, loss: 0.5318\n",
      "全部测试集：\n",
      "test  acc: 70.28%, loss: 0.5939\n",
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:48<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 74.39%, loss: 0.5243\n",
      "全部测试集：\n",
      "test  acc: 70.96%, loss: 0.5640\n",
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:48<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 74.60%, loss: 0.5163\n",
      "全部测试集：\n",
      "test  acc: 71.21%, loss: 0.5654\n",
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1272/1272 [06:48<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 74.94%, loss: 0.5106\n",
      "全部测试集：\n",
      "test  acc: 72.10%, loss: 0.5440\n"
     ]
    }
   ],
   "source": [
    "# net=load_new_model()\n",
    "# for epoch in range(200):\n",
    "#         print('epoch: %d' % epoch)\n",
    "#         train(celebA_train_loader,net,target_index=31,training_type=\"VGG16_origin_smiling\")\n",
    "#         acc=CelebA_test(net,target_index=31)\n",
    "#         if acc>90:\n",
    "#             print(\"epoch:\"+str(epoch))\n",
    "#             break\n",
    "# net=load_new_model()\n",
    "# for epoch in range(50):\n",
    "#         print('epoch: %d' % epoch)\n",
    "#         train(celebA_train_loader,net,target_index=6,training_type=\"VGG16_origin_biglips\")\n",
    "#         acc=CelebA_test(net,target_index=6)\n",
    "#         if acc>90:\n",
    "#             print(\"epoch:\"+str(epoch))\n",
    "#             break\n",
    "\n",
    "# net=load_new_model()\n",
    "# for epoch in range(25):\n",
    "#         print('epoch: %d' % epoch)\n",
    "#         train(celebA_train_loader,net,target_index=7,training_type=\"VGG16_origin_bignose\")\n",
    "#         acc=CelebA_test(net,target_index=7)\n",
    "#         if acc>90:\n",
    "#             print(\"epoch:\"+str(epoch))\n",
    "#             break\n",
    "net=load_new_model()\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_loader,net,target_index=33,training_type=\"VGG16_origin_wavyhair\")\n",
    "        acc=CelebA_test(net,target_index=33)\n",
    "        if acc>90:\n",
    "            print(\"epoch:\"+str(epoch))\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net=load_model('../models/VGG16(224*224)_origin_smiling_checkpoint.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部测试集：\n",
      "test  acc: 71.73%, loss: 0.7059\n",
      "性别1测试集：\n",
      "test  acc: 68.92%, loss: 0.7069\n",
      "性别2测试集：\n",
      "test  acc: 75.67%, loss: 0.6967\n",
      "标签1测试集：\n",
      "test  acc: 84.75%, loss: 0.6167\n",
      "标签2测试集：\n",
      "test  acc: 59.11%, loss: 0.7674\n"
     ]
    }
   ],
   "source": [
    "CelebA_test(net,target_index=target_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:27<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 64.74%, loss: 0.6459\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 71.83%, loss: 0.5081\n"
     ]
    }
   ],
   "source": [
    "#混淆训练,celebA数据集target为biglips\n",
    "for epoch in range(2):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_shuffle_biglips_dataloader,net,target_index=target_index,training_type=\"VGG16(224*224)_shuffle_smiling\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "net=load_model('../models/VGG16(224*224)_shuffle_smiling_checkpoint.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部测试集：\n",
      "test  acc: 33.74%, loss: 2.0693\n",
      "性别1测试集：\n",
      "test  acc: 33.47%, loss: 2.1568\n",
      "性别2测试集：\n",
      "test  acc: 34.91%, loss: 1.9318\n",
      "标签1测试集：\n",
      "test  acc: 38.15%, loss: 0.7709\n",
      "标签2测试集：\n",
      "test  acc: 29.84%, loss: 3.3945\n"
     ]
    }
   ],
   "source": [
    "CelebA_test(net,target_index=target_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.19%, loss: 0.2132\n",
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.63%, loss: 0.2047\n",
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.84%, loss: 0.1975\n",
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 88.89%, loss: 0.1970\n",
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.01%, loss: 0.1938\n",
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.12%, loss: 0.1897\n",
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.10%, loss: 0.1882\n",
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.12%, loss: 0.1880\n",
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:29<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.14%, loss: 0.1881\n",
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型训练中：: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:28<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 89.17%, loss: 0.1874\n"
     ]
    }
   ],
   "source": [
    "#恢复训练,celebA数据集target为biglips\n",
    "for epoch in range(10):\n",
    "        print('epoch: %d' % epoch)\n",
    "        train(celebA_train_balance_dataloader,net,target_index=target_index,training_type=\"VGG16(224*224)_balance_smiling\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "net=load_model('../models/VGG16(224*224)_balance_smiling_checkpoint.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全部测试集：\n",
      "test  acc: 72.26%, loss: 0.9061\n",
      "性别1测试集：\n",
      "test  acc: 70.07%, loss: 0.8734\n",
      "性别2测试集：\n",
      "test  acc: 75.74%, loss: 0.9761\n",
      "标签1测试集：\n",
      "test  acc: 82.18%, loss: 0.9227\n",
      "标签2测试集：\n",
      "test  acc: 61.94%, loss: 0.8948\n"
     ]
    }
   ],
   "source": [
    "CelebA_test(net,target_index=target_index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
